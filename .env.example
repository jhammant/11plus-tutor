# 11+ Tutor - Environment Configuration
# Copy this file to .env
#
# IMPORTANT: The app works WITHOUT an LLM!
# All 1,364 questions work out of the box. Only configure LLM if you want
# AI tutor chat features.

# =============================================================================
# APP MODE
# =============================================================================
# "opensource" = Free tier (all core features work without LLM)
APP_MODE=opensource

# =============================================================================
# LLM CONFIGURATION (OPTIONAL - see README.md for details)
# =============================================================================
# Choose ONE of the options below. Default works without LLM.

# --- DEFAULT: No LLM (all practice features work) ---
LLM_BINDING=openai
LLM_HOST=http://localhost:1234/v1
LLM_MODEL=not-configured
LLM_API_KEY=none

# --- Option: LM Studio (local, free, privacy-focused) ---
# 1. Download from https://lmstudio.ai
# 2. Search and download "llama 3.2" or "mistral"
# 3. Click "Start Server"
# LLM_BINDING=openai
# LLM_HOST=http://localhost:1234/v1
# LLM_MODEL=local-model
# LLM_API_KEY=lm-studio

# --- Option: Ollama (local, free, privacy-focused) ---
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Then: ollama pull llama3.2
# LLM_BINDING=ollama
# LLM_HOST=http://localhost:11434/v1/
# LLM_MODEL=llama3.2
# LLM_API_KEY=ollama

# --- Option: OpenAI (cloud, ~$0.01 per AI chat) ---
# Get key from: https://platform.openai.com/api-keys
# LLM_BINDING=openai
# LLM_HOST=https://api.openai.com/v1
# LLM_MODEL=gpt-4o-mini
# LLM_API_KEY=sk-your-key-here

# --- Option: Groq (cloud, FREE tier available!) ---
# Get key from: https://console.groq.com/keys
# LLM_BINDING=openai
# LLM_HOST=https://api.groq.com/openai/v1
# LLM_MODEL=llama-3.1-8b-instant
# LLM_API_KEY=gsk_your-key-here

# =============================================================================
# EMBEDDING (Only needed for advanced RAG features - ignore for basic use)
# =============================================================================
EMBEDDING_BINDING=ollama
EMBEDDING_HOST=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_API_KEY=ollama

# =============================================================================
# SERVER PORTS (change if ports are in use)
# =============================================================================
BACKEND_PORT=8002
FRONTEND_PORT=3783
